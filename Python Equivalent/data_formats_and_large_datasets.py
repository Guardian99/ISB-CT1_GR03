# -*- coding: utf-8 -*-
"""Data_Formats_and_Large_Datasets.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1Uz0w_MUhezJBB5Fn5bs2TLN2raUQ_Z-R

## Preparing the lab environment

- Create a dataset directory
- download the file to the *datasets* directory
"""

!mkdir datasets

"""### Download the dataset"""

!gdown 18Ulneqq0CSsuPPva9F4If-OFJkn7rj4M -O datasets/sigma.zip

ls -al datasets/

"""### Unzip the dataset"""

!unzip datasets/sigma.zip -d datasets/

!ls -al datasets/

"""## Benchmarking Various File Formats

- csv
- pickle
- feather
- parquet

### Reading the CSV File
"""

import pandas as pd
import os

# Commented out IPython magic to ensure Python compatibility.
# %%time
# 
# train_df = pd.read_csv("./datasets/train.csv")

train_df.dtypes

train_df.info()

train_df.shape

train_df.head(5)

"""### Optimizing data types"""

dtypes = {
    "channelGrouping": "str",
    "date": "int16",
    "device": "str",
    "fullVisitorId": "str",
    "geoNetwork": "str",
    "sessionId": "str",
    "socialEngagementType": "str",
    "totals": "str",
    "trafficSource": "str",
    "visitId": "uint16",
    "visitNumber": "int16",
    "visitStartTime": "uint16"
}

train_new_df = pd.read_csv("./datasets/train.csv", dtype = dtypes)

train_new_df.info()

"""### Creating other file formats"""

train_new_df.to_pickle("./datasets/train.pkl")

ls -al datasets/

ls -alh datasets/

train_new_df.to_parquet("./datasets/train.parquet")

!ls -al datasets/

train_new_df.to_feather("./datasets/train.feather")

!ls -al datasets/

### Comparing file sizes

##file_size = os.path.getsize('d:/file.jpg')

filenames = ['./datasets/train.csv',
             './datasets/train.pkl',
             './datasets/train.feather',
             './datasets/train.parquet']

all_filesizes = [os.path.getsize(f) for f in filenames]

filescompare_df = pd.DataFrame( { "formats" : filenames,
                                  "filesize": all_filesizes})

filescompare_df

import matplotlib.pyplot as plt
import seaborn as sn

plt.figure( figsize = (15, 5) )
sn.barplot( data = filescompare_df,
           x = 'formats',
           y = 'filesize');

"""### Read time benchmarking of different formats"""

# Commented out IPython magic to ensure Python compatibility.
# %%time
# 
# train_pkl_df = pd.read_pickle("./datasets/train.pkl")

# Commented out IPython magic to ensure Python compatibility.
# %%time
# 
# train_feather_df = pd.read_feather("./datasets/train.feather")

train_feather_df.shape

# Commented out IPython magic to ensure Python compatibility.
# %%time
# 
# train_parquet_df = pd.read_parquet("./datasets/train.parquet")

import time

t1 = time.perf_counter()
train_df = pd.read_csv("./datasets/train.csv")
time_csv = time.perf_counter() - t1

t1 = time.perf_counter()
train_pkl_df = pd.read_pickle("./datasets/train.pkl")
time_pkl = time.perf_counter() - t1

t1 = time.perf_counter()
train_feather_df = pd.read_feather("./datasets/train.feather")
time_feather = time.perf_counter() - t1

t1 = time.perf_counter()
train_parquet_df = pd.read_parquet("./datasets/train.parquet")
time_parquet = time.perf_counter() - t1

filescompare_df['read_time'] = [time_csv, time_pkl, time_feather, time_parquet]

filescompare_df

plt.figure( figsize = (15, 5) )
sn.barplot( data = filescompare_df,
           x = 'formats',
           y = 'read_time');

"""## Frameworks

- datatable (https://datatable.readthedocs.io/en/latest/index.html)
- dask
"""

!pip install datatable

import datatable as dt
print(dt.__version__)

# Commented out IPython magic to ensure Python compatibility.
# %%time
# 
# train_dtable = dt.fread("./datasets/train.csv")

train_df.head(5)

train_dtable_df = train_dtable.to_pandas()

train_dtable_df.info()

!pip install "dask[complete]"

import pandas as pd
import dask.dataframe as dd

# Commented out IPython magic to ensure Python compatibility.
# %%time
# 
# train_dask_df = dd.read_parquet("./datasets/train.parquet").compute()

train_dask_df.info()

train_dask_df.head(5)

train_dask_df.shape

train_dask_df.channelGrouping.unique()

